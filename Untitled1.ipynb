{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/jiaxin.gu/jupyter/asr_test/dataset/data_thchs30/\n"
     ]
    }
   ],
   "source": [
    "from feature.feature_prepare import thchs30,MagicData,primewords,ST_CMDS\n",
    "thchs30 = thchs30(\"/data/jiaxin.gu/jupyter/asr_test/dataset/data_thchs30\",label_file_type = 'trn')\n",
    "thchs30.read_label_file()\n",
    "from utils.file_wav import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_feature(file_dir):\n",
    "    wavsignal, fs = read_wav_data(file_dir)\n",
    "    feature_mat = np.array(GetFrequencyFeature3(wavsignal, fs))\n",
    "    \n",
    "    return np.pad(feature_mat,((0, 1600-feature_mat.shape[0]), (0, 0)),'constant')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id = dict(zip(thchs30.list_symbol,[i for i in range(len(thchs30.list_symbol))]))\n",
    "token2id[\"\"] = len(thchs30.list_symbol)\n",
    "id2token = dict(zip([i for i in range(len(thchs30.list_symbol))],thchs30.list_symbol))\n",
    "id2token[len(thchs30.list_symbol)] = \"\"\n",
    "vocab_dict = {\"id2token\": id2token, \"token2id\": token2id}\n",
    "def decode_model_output(output, blank=0):\n",
    "    \"\"\"\n",
    "    decode the output for every timestamp\n",
    "    :param output: the size of model_output, [batch_size, w, num_class], w is the final feature map's width\n",
    "    :param blank:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    batch_size, width, num_class = output.size()\n",
    "    output = output.max(dim=-1)[1].cpu().data.numpy()\n",
    "    result = []\n",
    "\n",
    "    for sample in output:\n",
    "        sample_result = []\n",
    "        for i in range(width - 1):\n",
    "            if sample[i] != sample[i - 1]:\n",
    "                sample_result.append(sample[i])\n",
    "        sample_result.append(sample[-1])\n",
    "        sample_result = np.asarray(sample_result, dtype=np.int32)\n",
    "        result.append(sample_result)\n",
    "\n",
    "    # filter blank\n",
    "    decoded_pred_label = [sample[sample != blank] for sample in result]\n",
    "    return decoded_pred_label\n",
    "\n",
    "\n",
    "def decode_model_output_verifycode(ctc_outputs, blank=0):\n",
    "    outputs = ctc_outputs.max(dim=-1)[1].cpu().data.numpy()\n",
    "    seq_len = outputs.shape[1]\n",
    "\n",
    "    rank_score = ctc_outputs.sort(dim=-1, descending=True)[0].detach().cpu().numpy()\n",
    "    rank_score = rank_score[:, :, :10]\n",
    "\n",
    "    rank_id = ctc_outputs.sort(dim=-1, descending=True)[1].cpu().numpy()\n",
    "    rank_id = rank_id[:, :, :10]\n",
    "\n",
    "    saveIdxList = []\n",
    "    preZeroIdx = -1\n",
    "\n",
    "    for i, sample in enumerate(outputs):\n",
    "        for idx in range(0, len(sample)):\n",
    "            x = sample[idx]\n",
    "            if x == 0:\n",
    "                preZeroIdx = idx\n",
    "                continue\n",
    "            if len(saveIdxList) == 0:  # 加入第一个确定保留元素的下标\n",
    "                saveIdxList.append(idx)\n",
    "                continue\n",
    "\n",
    "            preIdx = saveIdxList[-1]  # 最新的确定保留元素的下标\n",
    "            preNum = sample[preIdx]\n",
    "            if x == preNum and not (\n",
    "                    preIdx < preZeroIdx < idx):  # 中间没有0隔开，必然有A[preIdx] == A[preIdx + 1] == ... == A[idx - 1] == A[idx]\n",
    "                continue\n",
    "            else:  # 否则加入保留下标列表\n",
    "                saveIdxList.append(idx)\n",
    "\n",
    "    result_digits = outputs[0][saveIdxList]\n",
    "    result_id = rank_id[:, saveIdxList, :].squeeze(0)\n",
    "    result_score = rank_score[:, saveIdxList, :].squeeze(0)\n",
    "\n",
    "    return result_digits, result_id, result_score\n",
    "\n",
    "\n",
    "def cal_accuracy(output, labels, length, decoded_pred_label):\n",
    "    \"\"\"\n",
    "    compute the fully match accuary. firstly we need to decode labels through label length array,\n",
    "    as all labels in min-batch have been concated to list.\n",
    "    :param output: the size of model_output, [batch_size, w, num_class], w is the final feature map's width\n",
    "    :param labels: ground truth\n",
    "    :param length: length list for every sample\n",
    "    :param decoded_pred_label: decoded from model output\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # decode the training labels\n",
    "    decoded_gt_label = np.split(labels.data.numpy(), length.data.numpy().cumsum())[:-1]\n",
    "\n",
    "    batch_size, width, num_class = output.size()\n",
    "    result = []\n",
    "    for i in range(batch_size):\n",
    "        result.append(np.array_equal(decoded_gt_label[i], decoded_pred_label[i]))\n",
    "\n",
    "    accuracy = np.asarray(result).mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def levenshtein(s1, s2):\n",
    "    \"\"\"edit distance\"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[\n",
    "                             j + 1] + 1  # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1  # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "\n",
    "class ASRDataset(Dataset):\n",
    "    def __init__(self, label_dic,file_dic, usage = \"train\",transform=None):\n",
    "        self.label_dic = label_dic\n",
    "        self.file_dic = file_dic\n",
    "        self.usage = usage\n",
    "        self.transform = transform\n",
    "     \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        继承 Dataset 类后,必须重写的一个方法\n",
    "        返回数据集的大小\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        return len(self.file_dic[self.usage])\n",
    "     \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        继承 Dataset 类后,必须重写的一个方法\n",
    "        返回第 idx 个图像及相关信息\n",
    "        :param idx:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        feature_length = 2000\n",
    "        label_length = 40\n",
    "        file_name = self.file_dic[self.usage][idx]\n",
    "        wav_dir =  self.file_dic[\"file_dic\"]['wav'][file_name]\n",
    "        feature = self.load_wav_feature(wav_dir)\n",
    "        while feature.shape[1] < feature_length:\n",
    "            feature = np.concatenate((feature, feature), axis=1)\n",
    "        feature = feature[:,:feature_length]\n",
    "        feature = np.reshape(feature, [1, feature.shape[0], feature.shape[1]])\n",
    "        \n",
    "        feature = torch.Tensor(feature)\n",
    "        \n",
    "        #feature = torch.tensor(feature).float().unsqueeze(0)\n",
    "        label = self.label_dic[file_name]['code']\n",
    "        while len(label) < label_length:\n",
    "            label.extend(label)\n",
    "        label = label[:label_length]\n",
    "        # label拓展\n",
    "        \n",
    "        return feature,label,len(label)\n",
    "    \n",
    "    '''\n",
    "    def load_wav_feature(self, file_dir):\n",
    "        # wavsignal, fs = read_wav_data(file_dir)\n",
    "        # feature_mat = np.array(GetFrequencyFeature3(wavsignal, fs))\n",
    "        # return np.pad(feature_mat,((0, 1600-feature_mat.shape[0]), (0, 0)),'constant')\n",
    "        wav = wave.open(file_dir,\"rb\") # 打开一个wav格式的声音文件流\n",
    "        num_frame = wav.getnframes() # 获取帧数\n",
    "        num_channel = wav.getnchannels() # 获取声道数\n",
    "        # print(num_channel)\n",
    "        framerate = wav.getframerate() # 获取帧速率\n",
    "        num_sample_width = wav.getsampwidth() # 获取实例的比特宽度，即每一帧的字节数\n",
    "        str_data = wav.readframes(num_frame) # 读取全部的帧\n",
    "        wave_data = np.fromstring(str_data,dtype=np.short)\n",
    "        # 归一化\n",
    "        wave_data = wave_data * 1.0/max(abs(wave_data))\n",
    "        #将音频信号规整乘每行一路通道信号的格式，即该矩阵一行为一个通道的采样点，共nchannels行\n",
    "        wave_data = np.reshape(wave_data,[num_frame,num_channel]).T # .T 表示转置\n",
    "        wav.close()#关闭文件\n",
    "        frame_size = 512\n",
    "        fft_wave = fft(wave_data)\n",
    "        fft_wave_norm = fft(wave_data)/num_frame\n",
    "\n",
    "        NFFT = frame_size\n",
    "        overlap_size = 1.0/3 * frame_size #重叠部分采样点数overlapSize约为每帧点数的1/3~1/2\n",
    "        overlap_size = int(round(overlap_size))#取整\n",
    "        spectrum,freqs,ts,fig = plt.specgram(wave_data[0],NFFT = NFFT,Fs =framerate,window=np.hanning(M = frame_size),noverlap=overlap_size,mode='default',scale_by_freq=True,sides='default',scale='dB',xextent=None)#绘制频谱图         \n",
    "        return spectrum\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def load_wav_feature(self, file_dir):\n",
    "        wav = wave.open(file_dir,\"rb\") # 打开一个wav格式的声音文件流\n",
    "        num_frame = wav.getnframes() # 获取帧数\n",
    "        num_channel=wav.getnchannels() # 获取声道数\n",
    "        framerate=wav.getframerate() # 获取帧速率\n",
    "        num_sample_width=wav.getsampwidth() # 获取实例的比特宽度，即每一帧的字节数\n",
    "        str_data = wav.readframes(num_frame) # 读取全部的帧\n",
    "        wav.close() # 关闭流\n",
    "        wave_data = np.fromstring(str_data, dtype = np.short) # 将声音文件数据转换为数组矩阵形式\n",
    "        wave_data.shape = -1, num_channel # 按照声道数将数组整形，单声道时候是一列数组，双声道时候是两列的矩阵\n",
    "        wave_data = wave_data.T # 将矩阵转置\n",
    "        # wave_data = wave_data \n",
    "        # return wave_data, framerate\n",
    "        \n",
    "        \n",
    "        x=np.linspace(0, 400 - 1, 400, dtype = np.int64)\n",
    "        w = 0.54 - 0.46 * np.cos(2 * np.pi * (x) / (400 - 1) ) # 汉明窗\n",
    "        time_window = 25 # 单位ms\n",
    "        window_length = fs / 1000 * time_window # 计算窗长度的公式，目前全部为400固定值\n",
    "\n",
    "        wav_arr = np.array(wavsignal)\n",
    "        #wav_length = len(wavsignal[0])\n",
    "        wav_length = wav_arr.shape[1]\n",
    "\n",
    "        range0_end = int(len(wavsignal[0])/fs*1000 - time_window) // 10 # 计算循环终止的位置，也就是最终生成的窗数\n",
    "        data_input = np.zeros((range0_end, 200), dtype = np.float) # 用于存放最终的频率特征数据\n",
    "        data_line = np.zeros((1, 400), dtype = np.float)\n",
    "\n",
    "        for i in range(0, range0_end):\n",
    "            p_start = i * 160\n",
    "            p_end = p_start + 400\n",
    "            data_line = wav_arr[0, p_start:p_end]\n",
    "            data_line = data_line * w # 加窗\n",
    "            data_line = np.abs(fft(data_line)) / wav_length\n",
    "            data_input[i]=data_line[0:200] # 设置为400除以2的值（即200）是取一半数据，因为是对称的\n",
    "\n",
    "        #print(data_input.shape)\n",
    "        data_input = np.log(data_input + 1)\n",
    "        return data_input\n",
    "\n",
    "        \n",
    "    \n",
    "ASRDataset_ = ASRDataset(thchs30.label_dic,thchs30.file_dic,\"train\")\n",
    "\n",
    "\n",
    "def aligin_collate(batch_size):\n",
    "    \"\"\"process variable length labels \"\"\"\n",
    "    wave_list = list()\n",
    "    label_list = list()\n",
    "    length_list = list()\n",
    "    for _, (wave, label, length) in enumerate(batch_size):\n",
    "        wave_list.append(wave)\n",
    "        label_list.extend(label)\n",
    "        length_list.append(length)\n",
    "\n",
    "    stacked_wave = torch.stack(wave_list, dim=0)\n",
    "    label = torch.IntTensor(np.array(label_list))\n",
    "    length = torch.IntTensor(np.array(length_list))\n",
    "\n",
    "    return stacked_wave, label, length\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(ASRDataset_,\n",
    "                                           batch_size=3,\n",
    "                                           collate_fn=aligin_collate,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True,\n",
    "                                           num_workers=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thchs30Dataset_ = ASRDataset(thchs30.label_dic,thchs30.file_dic,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from warpctc_pytorch import CTCLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 18-3-27 下午2:26\n",
    "# @Author  : junhao.li\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math\n",
    "\n",
    "use_cuda = 1\n",
    "torch.manual_seed(2019)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        padding = dilation\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=padding, dilation=dilation,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Resnet_GRU_model(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN + RNN as the Encoder, the CNN part is self defined residual net,\n",
    "    and the RNN part we use two layers GRU, replace average pooling\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bottleneck, num_class, rnn_hidden_size=200, dropout=0):\n",
    "        super(Resnet_GRU_model, self).__init__()\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.inplanes = 64\n",
    "        # Module list\n",
    "        # [3 * 32 * 280] ==> [64 * 16 * 140]\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, padding=1, stride=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # after layer_1: [128 * 16 * 140]\n",
    "        self.layer_1 = self._make_layer(bottleneck, 32, blocks=3, stride=1, dilation=1)\n",
    "        # after layer_2: [256 * 8 * 70]\n",
    "        self.layer_2 = self._make_layer(bottleneck, 64, blocks=4, stride=2, dilation=2)\n",
    "        # after layer_3: [256 * 8 * 70]\n",
    "        self.layer_3 = self._make_layer(bottleneck, 64, blocks=5, stride=1, dilation=2)\n",
    "        # after layer_4: [256 * 1 * 70]\n",
    "        # self.layer_4 = nn.AvgPool2d(kernel_size=(8, 1), padding=(0, 0), stride=1)\n",
    "        self.layer_4 = nn.MaxPool2d(kernel_size=(64, 1), padding=(0, 0), stride=1)\n",
    "        # RNN\n",
    "        self.gru_1 = nn.GRU(input_size=256,\n",
    "                            hidden_size=self.rnn_hidden_size,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        self.gru_2 = nn.GRU(input_size=self.rnn_hidden_size * 2,\n",
    "                            hidden_size=self.rnn_hidden_size,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(1856, num_class)\n",
    "\n",
    "        # weight initiation\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                *[nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                  nn.BatchNorm2d(planes * block.expansion)])\n",
    "\n",
    "        layers = list()\n",
    "        layers.append(block(self.inplanes, planes, stride=stride, dilation=dilation, downsample=downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, stride=1, dilation=dilation, downsample=None))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def init_rnn_weight(self, batch_size, rnn_hidden_size):\n",
    "        h = Variable(torch.rand(2, batch_size, rnn_hidden_size), requires_grad=True)\n",
    "        h = h.cuda() if use_cuda else h\n",
    "        return h\n",
    "\n",
    "    def forward(self, x, h1=None, h2=None):\n",
    "\n",
    "        batch_size = x.size()[0]\n",
    "        \n",
    "        h1 = self.init_rnn_weight(batch_size, self.rnn_hidden_size) if h1 is None else h1\n",
    "        rnn_x = x.squeeze(1)\n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)        \n",
    "        print(x.shape)\n",
    "\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # added\n",
    "        # layer_1 ~ layer_4: \n",
    "        x = self.layer_1(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer_2(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer_3(x)\n",
    "        print(x.shape)\n",
    "        x = self.layer_4(x)\n",
    "        print(\"layer_4\",x.shape)\n",
    "        \n",
    "        # after average pooling the feature map: [batch_size, 256, 1, 70]\n",
    "        # remove dim = 1，as RNN model has this limit, only support three dim\n",
    "        # [batch_size, num_feature_map, 1, w]  ==> [batch_size, num_feature_map, w]\n",
    "        x = x.squeeze(2)\n",
    "        print(\"squeeze\",x.shape)\n",
    "        x = x.transpose(1, 2)  # [batch_size, w, num_feature_map]\n",
    "        cnn_feature = x\n",
    "        print(\"transpose\",x.shape)\n",
    "        # after the first bidirectional GRU module, [batch_size, 70, 256]  ==> [batch_size, 70, 256 * 2]\n",
    "        # after the second  bidirectional GRU module, [batch_size, 70, 256 * 2]  ==> [batch_size, 70, 256 * 2]\n",
    "        x, rnn_h1 = self.gru_1(x, h1)\n",
    "        # residual = x\n",
    "        print(x.shape)\n",
    "        x, rnn_h2 = self.gru_2(x, rnn_h1)\n",
    "        print(x.shape)\n",
    "        # x = x + residual\n",
    "\n",
    "        rnn_feature = x.transpose(1, 2)\n",
    "\n",
    "        x = torch.cat((cnn_feature, rnn_feature), dim=2)\n",
    "        # fully connected layers\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        return x, rnn_h1, rnn_h2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:86: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:86: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:86: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:86: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:86: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:86: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:86: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:86: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "Traceback (most recent call last):\n  File \"/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-13-58a2be5b8cc8>\", line 31, in __getitem__\n    feature = self.load_wav_feature(wav_dir)\n  File \"<ipython-input-13-58a2be5b8cc8>\", line 96, in load_wav_feature\n    window_length = fs / 1000 * time_window # 计算窗长度的公式，目前全部为400固定值\nNameError: name 'fs' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4c48c8117386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miters\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_inter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training finished: epoch:{}, iters:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-4c48c8117386>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: Traceback (most recent call last):\n  File \"/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/data/jiaxin.gu/anaconda3/envs/tf/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-13-58a2be5b8cc8>\", line 31, in __getitem__\n    feature = self.load_wav_feature(wav_dir)\n  File \"<ipython-input-13-58a2be5b8cc8>\", line 96, in load_wav_feature\n    window_length = fs / 1000 * time_window # 计算窗长度的公式，目前全部为400固定值\nNameError: name 'fs' is not defined\n"
     ]
    }
   ],
   "source": [
    "net = Resnet_GRU_model(Bottleneck, num_class=thchs30.SymbolNum, rnn_hidden_size=200, dropout=0)\n",
    "use_cuda = 1\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    cudnn.benchmark = True\n",
    "from collections import OrderedDict\n",
    "\n",
    "if False:\n",
    "    pre_trained_model = torch.load(\"./model_save/ASR_001_001000.pth\", map_location=lambda storage, loc: storage)\n",
    "    # 新建一个state_dict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in pre_trained_model.items():\n",
    "        new_key = k\n",
    "        # new_key = '.'.join(k.split('.')[1:])\n",
    "        new_state_dict[new_key] = v\n",
    "    net.load_state_dict(new_state_dict)\n",
    "    print('load model finished...')\n",
    "total_epoch = 5\n",
    "model_name = \"ASR\"\n",
    "model_dict_save_path = \"./model_save/\"\n",
    "\n",
    "criterion = CTCLoss()\n",
    "learn_rate = 0.001\n",
    "optimizer = optim.Adam(net.parameters(), lr=learn_rate, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, factor):\n",
    "    lr = learn_rate / factor\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "save_model_iter = min(len(train_loader) - 1, 100)\n",
    "batch_len = len(train_loader)\n",
    "start_epoch = 1\n",
    "max_inter = 300000\n",
    "decrate_1 = 100000\n",
    "decrate_2 = 150000\n",
    "iters = 0\n",
    "\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    h1, h2 = None, None\n",
    "    for batch_idx, (feature, label, length) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            feature = feature.cuda()\n",
    "        feature = Variable(feature)\n",
    "        label = Variable(label, requires_grad=False).contiguous()\n",
    "        length = Variable(length, requires_grad=False).contiguous()\n",
    "        output, h1, h2 = net(feature, h1, h2)\n",
    "        h1.detach_(), h2.detach_()\n",
    "        h1, h2 = Variable(h1.data, requires_grad=True), Variable(h2.data, requires_grad=True)\n",
    "\n",
    "        # compute loss\n",
    "        batch_size, width, num_class = output.size()\n",
    "        predict_len = Variable(torch.IntTensor(batch_size * [width]), requires_grad=False)\n",
    "        # [batch_size, w, num_class] ==> [w, batch_size, num_class]\n",
    "        model_output = output.transpose(0, 1)\n",
    "        loss = criterion(model_output, label, predict_len, length)\n",
    "\n",
    "        global iters\n",
    "        iters += 1\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        lr = learn_rate\n",
    "        if decrate_1 <= iters < decrate_2:\n",
    "            adjust_learning_rate(optimizer, 10.0)\n",
    "            lr = learn_rate / 10.0\n",
    "        if iters >= decrate_2:\n",
    "            adjust_learning_rate(optimizer, 100.0)\n",
    "            lr = learn_rate / 100.0\n",
    "\n",
    "        # loss.backward(retain_graph=True)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(net.parameters(), 10.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        # compute accuracy\n",
    "        decoded_pred_label = decode_model_output(output, blank=0)\n",
    "        accuracy = cal_accuracy(output, label, length, decoded_pred_label)\n",
    "        train_accuracy += accuracy\n",
    "\n",
    "        # loss info\n",
    "        info_str = 'epoch:{}/{}:batch:{}/{}/{},lr:{}==>batch loss:{}, ave_train_loss:{}'\n",
    "        batch_info = info_str.format('%03d' % epoch,\n",
    "                                     total_epoch,\n",
    "                                     '%06d' % batch_idx,\n",
    "                                     '%05d' % batch_len,\n",
    "                                     '%06d' % iters,\n",
    "                                     lr,\n",
    "                                     loss.data[0],\n",
    "                                     train_loss / (batch_idx + 1))\n",
    "        print(batch_info)\n",
    "        # accuracy\n",
    "        accuracy_str = 'epoch:{}/{}:batch:{}/{}/{},lr:{}==>batch accuracy:{}, ave_train_accuracy:{}'\n",
    "        accuracy_info = accuracy_str.format('%03d' % epoch,\n",
    "                                            total_epoch,\n",
    "                                            '%06d' % batch_idx,\n",
    "                                            '%05d' % batch_len,\n",
    "                                            '%06d' % iters,\n",
    "                                            lr,\n",
    "                                            accuracy,\n",
    "                                            train_accuracy / (batch_idx + 1))\n",
    "        if train_accuracy > 0:\n",
    "            print(accuracy_info)\n",
    "\n",
    "        if batch_idx > 0 and batch_idx % save_model_iter == 0:\n",
    "            torch.save(net.state_dict(), \"{}/{}_{}_{}.pth\".format(model_dict_save_path,\n",
    "                                                                  model_name,\n",
    "                                                                  '%03d' % epoch,\n",
    "                                                                  '%06d' % batch_idx))\n",
    "        if iters == max_inter:\n",
    "            torch.save(net.state_dict(), \"{}/{}_{}_{}.pth\".format(model_dict_save_path,\n",
    "                                                                  model_name,\n",
    "                                                                  '%03d' % epoch,\n",
    "                                                                  '%06d' % batch_idx))\n",
    "            break\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, total_epoch):\n",
    "    if iters <= max_inter:\n",
    "        train(epoch)\n",
    "    else:\n",
    "        print('training finished: epoch:{}, iters:{}'.format(epoch + 1, iters))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.randn([3, 256, 400, 50])\n",
    "b = torch.nn.MaxPool2d(kernel_size=(20, 50), padding=(0, 0), stride=1)\n",
    "c = b(temp)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
